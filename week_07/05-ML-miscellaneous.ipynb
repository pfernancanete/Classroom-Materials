{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dying-schema",
   "metadata": {},
   "source": [
    " # Hyperparameter Tuning - Feature engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-christian",
   "metadata": {},
   "source": [
    "![nohayjupytersingif](https://media.giphy.com/media/jeDM590qtCP9C/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-stack",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Feature-engineering\" data-toc-modified-id=\"Feature-engineering-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Feature engineering</a></span></li><li><span><a href=\"#Categorical-encoding\" data-toc-modified-id=\"Categorical-encoding-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Categorical encoding</a></span><ul class=\"toc-item\"><li><span><a href=\"#Label-Encoder\" data-toc-modified-id=\"Label-Encoder-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Label Encoder</a></span></li><li><span><a href=\"#One-Hot-Encoder\" data-toc-modified-id=\"One-Hot-Encoder-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>One Hot Encoder</a></span></li><li><span><a href=\"#A-mano-con-un-diccionario-üí°\" data-toc-modified-id=\"A-mano-con-un-diccionario-üí°-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>A mano con un diccionario üí°</a></span></li></ul></li><li><span><a href=\"#Feature-Scaling\" data-toc-modified-id=\"Feature-Scaling-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Feature Scaling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Estandarizaci√≥n\" data-toc-modified-id=\"Estandarizaci√≥n-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Estandarizaci√≥n</a></span></li><li><span><a href=\"#Normalizaci√≥n\" data-toc-modified-id=\"Normalizaci√≥n-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Normalizaci√≥n</a></span></li><li><span><a href=\"#Cito-a-Andriy-Burkov:\" data-toc-modified-id=\"Cito-a-Andriy-Burkov:-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Cito a Andriy Burkov:</a></span></li></ul></li><li><span><a href=\"#Repasamos-Train-Test-Split\" data-toc-modified-id=\"Repasamos-Train-Test-Split-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Repasamos Train Test Split</a></span></li><li><span><a href=\"#Ajuste-de-hiperpar√°metros\" data-toc-modified-id=\"Ajuste-de-hiperpar√°metros-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Ajuste de hiperpar√°metros</a></span><ul class=\"toc-item\"><li><span><a href=\"#--Muestreo-aleatorio\" data-toc-modified-id=\"--Muestreo-aleatorio-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>- Muestreo aleatorio</a></span></li><li><span><a href=\"#--Muestreo-de-cuadr√≠cula\" data-toc-modified-id=\"--Muestreo-de-cuadr√≠cula-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>- Muestreo de cuadr√≠cula</a></span></li><li><span><a href=\"#--Muestreo-bayesiano\" data-toc-modified-id=\"--Muestreo-bayesiano-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>- Muestreo bayesiano</a></span></li><li><span><a href=\"#GridSearchCV-de-sklearn,-¬°saludad-a-vuestro-nuevo-amigo!\" data-toc-modified-id=\"GridSearchCV-de-sklearn,-¬°saludad-a-vuestro-nuevo-amigo!-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>GridSearchCV de sklearn, ¬°saludad a vuestro nuevo amigo!</a></span></li><li><span><a href=\"#Entrenar√≠amos-el-modelo-con-los-mejores-par√°metros\" data-toc-modified-id=\"Entrenar√≠amos-el-modelo-con-los-mejores-par√°metros-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Entrenar√≠amos el modelo con los mejores par√°metros</a></span></li></ul></li><li><span><a href=\"#Salvar-/-Exprotar-el-modelo\" data-toc-modified-id=\"Salvar-/-Exprotar-el-modelo-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Salvar / Exprotar el modelo</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-holly",
   "metadata": {},
   "source": [
    "##¬†Feature engineering\n",
    "Es el proceso de utilizar el conocimiento del dominio para extraer caracter√≠sticas de los datos brutos. Estas caracter√≠sticas pueden utilizarse para mejorar el rendimiento de los algoritmos de aprendizaje autom√°tico. La ingenier√≠a de caracter√≠sticas puede considerarse como un aprendizaje autom√°tico aplicado en s√≠ mismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../datasets/titanic.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-consequence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-submission",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-opera",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-selection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "described-farming",
   "metadata": {},
   "source": [
    "Hay muchos valores que faltan, pero debemos utilizar la variable del camarote porque puede ser un predictor importante. Como puede ver en la siguiente imagen, la primera clase ten√≠a los camarotes en la cubierta A, B o C, una mezcla estaba en la D o la E y la tercera clase estaba principalmente en la f o la g. Podemos identificar la cubierta por la primera letra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-consent",
   "metadata": {},
   "source": [
    "![laimagendelbarco](../images/barco.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-timothy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-island",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "criminal-fountain",
   "metadata": {},
   "source": [
    "El nombre nos proporciona informaci√≥n muy importante sobre el estatus socioecon√≥mico de un pasajero. Podemos responder a la pregunta de si alguien est√° casado o no o si tiene un t√≠tulo formal que podr√≠a ser un indicador de un estatus social m√°s alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-chosen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-actress",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-storage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-offense",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-colors",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-sacramento",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-marriage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-serial",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-aquarium",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-approach",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "jewish-planet",
   "metadata": {},
   "source": [
    "Solo nos queda la columna Age con nulos ... Vamos a rellenarlos, pero explorando los datos.... ¬øtienen la misma edad de media los hombres que las mujeres?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-pottery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-quality",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "mexican-trigger",
   "metadata": {},
   "source": [
    "Por ajustarnos un poco m√°s, vamos a rellenar los NaN de la edad con la mediana pero en funci√≥n de su sexo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-beverage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-delivery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-still",
   "metadata": {},
   "source": [
    "## Categorical encoding\n",
    "\n",
    "Con una linea de import en nuestro c√≥digo, se abren posibilidades nuevas en opciones a como modelar o manipular nuestro dataset.\n",
    "\n",
    "Anteriormente comentamos en el post de dummies la posibilidad de generar con la funci√≥n get_dummies() y transformar cada dato no num√©rico en una representaci√≥n binaria ( expandiendo nuestro dataset a la cantidad de datos distintos que existan en una columna)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-security",
   "metadata": {},
   "source": [
    "###¬†Label Encoder\n",
    "Pros y contras\n",
    "- Si tenemos categor√≠as que tienen valor en s√≠ mismas, como \"bueno, malo, regular\" lo ideal ser√≠a no dejar que LabelEncoder lo haga de forma autom√°tica si no aplicarlo nosotras a mano, ya que el valor que ponemos puede influir en el peso que el algoritmo le da a esas variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-cotton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-senior",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-strand",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-server",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-aquarium",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-serial",
   "metadata": {},
   "source": [
    "### One Hot Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-cleaners",
   "metadata": {},
   "source": [
    "Ahora bien, como ya hemos comentado, dependiendo de los datos que tengamos, podr√≠amos encontrarnos con situaciones en las que, tras la codificaci√≥n de las etiquetas, podr√≠amos confundir a nuestro modelo haci√©ndole creer que una columna tiene datos con alg√∫n tipo de orden o jerarqu√≠a, cuando claramente no lo tenemos. Para evitar esto, \"OneHotEncode\" esa columna.\n",
    "Lo que hace una codificaci√≥n en caliente es que toma una columna que tiene datos categ√≥ricos, que ha sido codificada con etiquetas, y luego divide la columna en m√∫ltiples columnas. Los n√∫meros son reemplazados por 1s y 0s, dependiendo de qu√© columna tiene qu√© valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-haiti",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regular-machine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehotencoder = OneHotEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-macintosh",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-biotechnology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-temperature",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "regular-allah",
   "metadata": {},
   "source": [
    "###¬†A mano con un diccionario üí°\n",
    "Podremos otorgarle un valor num√©rico a cada categor√≠a y decidimos su importancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-offer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-joshua",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_para_hot = { \"M\": 1,\n",
    "                \"C\": 2,\n",
    "                \"E\": 3,\n",
    "                \"G\":4,\n",
    "                \"D\":5,\n",
    "                \"A\":6,\n",
    "                \"B\":7,\n",
    "                \"F\":8,\n",
    "                \"T\":9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-drain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-smith",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-treat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-mattress",
   "metadata": {},
   "source": [
    "##¬†Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-portsmouth",
   "metadata": {},
   "source": [
    "Algunos algoritmos, especialmente los que se basan en c√°lculos de distancia, dar√°n m√°s peso a las caracter√≠sticas que muestren grandes cambios de valor, interpretando estas caracter√≠sticas como artificialmente m√°s importantes. Para estos algoritmos, es importante que escalemos nuestros rasgos, o que pongamos en la misma escala rasgos con escalas naturalmente diferentes, para que los rasgos sean utilizados por el algoritmo sin una sobreponderaci√≥n artificial, y permita comparar dos rasgos con escalas diferentes.      \n",
    "Hay dos tipos diferentes de escalamiento de caracter√≠sticas que vamos a explorar:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-canon",
   "metadata": {},
   "source": [
    "### Estandarizaci√≥n   \n",
    "En la estandarizaci√≥n, imponemos varias propiedades estad√≠sticas a la variable: el valor medio se fija en 0, y la desviaci√≥n est√°ndar se fija en 1. Esto se consigue restando la media de cada valor de la caracter√≠stica y dividiendo por la desviaci√≥n est√°ndar. Esto tambi√©n se llama a veces \"normalizaci√≥n de la puntuaci√≥n z\". \n",
    "\n",
    "Entonces, ¬øqu√© significa esto, en la pr√°ctica, sobre los datos estandarizados? Como podemos ver a continuaci√≥n, ahora tenemos las distribuciones de ambas variables centradas alrededor de la media cero, con una desviaci√≥n est√°ndar de 1. Como estamos imponiendo esta desviaci√≥n est√°ndar, la normalizaci√≥n reduce los efectos de los valores at√≠picos en la caracter√≠stica. Adem√°s, permite comparar dos caracter√≠sticas con escalas o unidades diferentes. Las diferentes escalas de las caracter√≠sticas se reflejar√≠an estad√≠sticamente en diferencias tanto en la media como en la desviaci√≥n est√°ndar. La estandarizaci√≥n de estos dos n√∫meros entre caracter√≠sticas elimina la influencia de estas diferencias de escala.\n",
    "\n",
    "La estandarizaci√≥n es especialmente importante en situaciones en las que utilizamos algoritmos que asumen que las caracter√≠sticas de nuestros datos se distribuyen en una 'curva de campana' o una distribuci√≥n gaussiana, como la regresi√≥n lineal y log√≠stica. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "En este dataset no nos enfrentamos a un problema de regresi√≥n si no de clasificaci√≥n,\n",
    "pero vamos a hacer un ejemplo de estandarizaci√≥n en una columna para ver el c√≥digo\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-minnesota",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-religious",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-superintendent",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-shanghai",
   "metadata": {},
   "source": [
    "### Normalizaci√≥n\n",
    "\n",
    "En la otra forma de escalado de caracter√≠sticas, llamada normalizaci√≥n, la caracter√≠stica se reescala a un rango entre 0 y 1, sin ning√∫n cambio en su distribuci√≥n original dentro de ese rango. Matem√°ticamente, esto se consigue restando el valor m√≠nimo de la caracter√≠stica a cada valor de la misma, y dividiendo por la diferencia entre el valor mayor y el valor m√≠nimo. \n",
    "\n",
    "Dado que calculamos el valor normalizado utilizando los valores m√°ximo y m√≠nimo de la caracter√≠stica, esta t√©cnica se denomina a veces \"normalizaci√≥n min-max\".      \n",
    "La normalizaci√≥n es m√°s √∫til en los casos en que sus datos tienen pocos valores at√≠picos pero rangos muy variables, usted no sabe c√≥mo se distribuyen sus datos, o sabe que no se distribuyen en una curva de campana (gaussiana). Generalmente se aplica con algoritmos que no hacen suposiciones sobre las distribuciones de las caracter√≠sticas.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = Normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-monster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-sacrifice",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-freeze",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "legislative-favor",
   "metadata": {},
   "source": [
    "###¬†Cito a Andriy Burkov:\n",
    "Te estar√°s preguntando cu√°ndo se debe utilizar la normalizaci√≥n y cu√°ndo la estandarizaci√≥n. No hay una respuesta definitiva a esta pregunta. Por lo general, si su conjunto de datos no es demasiado grande y tiene tiempo, puede probar ambos y ver cu√°l de ellos se adapta mejor a su tarea.\n",
    "Si no tiene tiempo para realizar varios experimentos, como regla general:\n",
    "\n",
    "- Los algoritmos de aprendizaje no supervisado, en la pr√°ctica, se benefician m√°s de la estandarizaci√≥n que de la normalizaci√≥n.      \n",
    "- La estandarizaci√≥n tambi√©n es preferible para una caracter√≠stica si los valores que √©sta toma se distribuyen cerca de una distribuci√≥n normal (la llamada curva de campana).     \n",
    "- Una vez m√°s, la normalizaci√≥n es preferible para una caracter√≠stica si a veces puede tener valores extremadamente altos o bajos (valores at√≠picos); esto se debe a que la normalizaci√≥n \"exprimir√°\" los valores normales en un rango muy peque√±o.       \n",
    "- En todos los dem√°s casos, es preferible la normalizaci√≥n.      \n",
    "\n",
    "El reescalado de caracter√≠sticas suele ser beneficioso para la mayor√≠a de los algoritmos de aprendizaje. Sin embargo, las implementaciones modernas de los algoritmos de aprendizaje, que se pueden encontrar en bibliotecas populares, son robustas a las caracter√≠sticas que se encuentran en diferentes rangos.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-concern",
   "metadata": {},
   "source": [
    "##¬†Repasamos Train Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a preparar los datos (X, y) antes de entrenar el modelo y ajustar los hiperpar√°metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-jason",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-sport",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-affect",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-saver",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "revised-harrison",
   "metadata": {},
   "source": [
    "## Ajuste de hiperpar√°metros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-concentration",
   "metadata": {},
   "source": [
    "¬øQu√© es el ajuste de hiperpar√°metros?\n",
    "Los hiperpar√°metros son par√°metros ajustables que permiten controlar el proceso de entrenamiento de un modelo. Por ejemplo, con redes neuronales, puede decidir el n√∫mero de capas ocultas y el n√∫mero de nodos de cada capa. El rendimiento de un modelo depende en gran medida de los hiperpar√°metros.\n",
    "El ajuste de hiperpar√°metros, tambi√©n denominado optimizaci√≥n de hiperpar√°metros es el proceso de encontrar la configuraci√≥n de hiperpar√°metros que produzca el mejor rendimiento. Normalmente, el proceso es manual y costoso desde el punto de vista computacional.\n",
    "\n",
    "Hay diferentes t√©cnicas para elegir este ajuste de hiperpar√°metros:     \n",
    "    \n",
    "### - Muestreo aleatorio    \n",
    "El muestreo aleatorio admite hiperpar√°metros discretos y continuos. Admite la terminaci√≥n anticipada de las series de bajo rendimiento. Algunos usuarios realizan una b√∫squeda inicial con muestreo aleatorio y luego restringen el espacio de b√∫squeda para mejorar los resultados.\n",
    "En el muestreo aleatorio, los valores de hiperpar√°metro se seleccionan aleatoriamente del espacio de b√∫squeda definido.\n",
    "\n",
    "### - Muestreo de cuadr√≠cula\n",
    "El muestreo de cuadr√≠cula admite hiperpar√°metros discretos. Use el muestreo de cuadr√≠cula si su presupuesto le permite buscar en el espacio de b√∫squeda de manera exhaustiva. Admite la terminaci√≥n anticipada de las series de bajo rendimiento.\n",
    "\n",
    "### - Muestreo bayesiano   \n",
    "El muestreo bayesiano se basa en el algoritmo de optimizaci√≥n bayesiano. Escoge las muestras en funci√≥n de c√≥mo lo hicieron las anteriores, para que las nuevas muestras mejoren la m√©trica principal.\n",
    " Para obtener los mejores resultados, se recomienda que el n√∫mero m√°ximo de series sea mayor o igual que 20 veces el n√∫mero de hiperpar√°metros que se est√° optimizando.\n",
    "El n√∫mero de series simult√°neas afecta a la eficacia del proceso de ajuste. Un menor n√∫mero de series simult√°neas puede provocar una mejor convergencia de muestreo, dado que el menor grado de paralelismo aumenta el n√∫mero de series que se benefician de las series completadas previamente.\n",
    "\n",
    "Vamos a ver el ajuste de hiperpar√°metros en cuadr√≠cula con GridSearchCV pero os dejo que investigu√©is el muestreo bayesiano con [HyperOpt](https://towardsdatascience.com/hyperopt-hyperparameter-tuning-based-on-bayesian-optimization-7fa32dffaf29)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-electron",
   "metadata": {},
   "source": [
    "###¬†GridSearchCV de sklearn, ¬°saludad a vuestro nuevo amigo!\n",
    "Y leed la [documentaci√≥n](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hiperpar√°metros tuneables de RandomForest\n",
    "parameters = {'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reducimos para hacer la prueba con diferentes n_estimators\n",
    "params = {\n",
    "     'n_estimators': [400, 600,800]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-latitude",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-rings",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-metabolism",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-merchandise",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "resistant-pointer",
   "metadata": {},
   "source": [
    "###¬†Entrenar√≠amos el modelo con los mejores par√°metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-check",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-vanilla",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-vermont",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-mouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Accuracy\", round(accuracy_score(y_test,y_pred),3))\n",
    "print(\"Precission\",round(precision_score(y_test,y_pred, average = \"weighted\"),3))\n",
    "print(\"Recall\", round(recall_score(y_test,y_pred, average = \"weighted\"),3))\n",
    "print(\"F1_score\", round(f1_score(y_test,y_pred,average= \"weighted\"),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-abraham",
   "metadata": {},
   "source": [
    "##¬†Salvar / Exprotar el modelo\n",
    "https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-genealogy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-yacht",
   "metadata": {},
   "outputs": [],
   "source": [
    "#¬†save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(rfc_params, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "ironhack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
